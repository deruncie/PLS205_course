---
title: "Lab 3. Experiments with >2 treatment levels and subsamples"
author: Daniel Runcie.
output: 
 html_notebook:
    toc: true
    toc_float: true
---

```{r}
# Necessary pacakges 
library(ggplot2) 
library(emmeans)
# the following 5 packages are new. You may have to install these using install.packages(c('car','lme4','lmerTest','pbkrtest','multcomp'))
library(car)
library(lme4)
library(lmerTest)
library(pbkrtest)
library(multcomp)
```


## An experiment with a multi-level treatment and subsamples of the experimental unit.

In the following experiment, the nitrogen fixation capacities of six different strains of rhizobia on clover are compared. 
The experiment was set up in a field of clover divided into a 5 x 6 grid of plots.
6 treatments (i.e. 5 new strains plus a control) were randomly assigned to the 30 plots, so 5 plots received each treatment.
At the end of the experiment, four samples of soil were collected from random locations within each plot 
and the nitrogen content of each soil sample was quantified separately.

### Design table
The Experimental Design table for this experiment can be written as this:

**Design**: Completely randomized design with subsamples of the experimental units

| Structure | Variable | Type        | # levels | Experimental Unit |
|-----------|----------|-------------|----------|-------------------|
| Treatment | Strain   | Categorical | 6        | Plot              |
| Design    | Plot     | Categorical | 30       |                   |
| Design    | Sample   | Categorical | 120      |                   |
| Response  | NLevel   | Numeric     | 120      |                   |


> Thought Question:
>
> Is the above table complete? Are there any other Variables that might be useful to include? 
> 
> What types of comparisons among treatments would be most interesting? 

- Since the plots are arrayed in a grid, we might record the position of the plot in the grid (ie row and column)
- We might also want to record the order of sampling.
- We could compare each new strain to the control. 
- Or we could compare all pairs of strains.
- Or we could test the hypothesis that all strains are equivalent.

### Load the data table

Load the data and check that it was loaded correctly:
```{r}
clover <- read.csv('Clover_data.csv')
str(clover)
```

`Strain` is a Factor with 6 levels, and `NLevel` is numeric data. That is good
`Plot` should be a factor with 30 levels, but is an `int` with 30 values. You can see it is an `int` above. To see the number of values, you can do:
```{r}
unique(clover$Plot)
```
It's not important for this analysis, but in general we should fix this turn Plot into a factor:
```{r}
clover$Plot = factor(clover$Plot)
```
Sample should be a factor with 120 levels. But if we look, we see it only has 4:
```{r}
unique(clover$Sample)
```
Probably, the researcher just numbered the four samples for each Plot 1..4. We can verify this with the `table()` function:
```{r}
table(clover$Sample,clover$Plot)
```
This shows that each combination of `Sample` (rows) and `Plot` (columns) has a single row in the data.
It would be better if the Samples were named uniquely. One way to do this is to paste the Plot name and the Sample name together like this:
```{r}
clover$Sample <- interaction(clover$Plot,clover$Sample,drop = TRUE)
```
This is called **nesting** `Sample` within `Plot`.

Now, our data table is consistent with our design table:
```{r}
str(clover)
```

## Analyzing the data

As we showed in Lab 2, data analysis in R consists of three steps:

1. Visualize the data
2. Fit a model to the data
3. Run model diagnostics to check model assumptions
4. Use the model fit to calculate summary statistics and draw conclusions

### Visualize the data
Let's start by plotting the data to visually inspect.
A simple plot for a one-treatment experiment is a boxplot, like we've seen in class
```{r}
# library(ggplot2) # use this line only if you haven't yet loaded ggplot2 in your session
ggplot(clover,aes(x=Strain,y=NLevel)) + geom_boxplot() + geom_jitter()
```
> Thought Question:
>
> This plot is a bit missleading. Why?

It's missleading because it looks like we have 20 independent observations for each Strain. 
But we don't - we only have 5 experimental units. So our plot should really just show the experimental units, 
or at least collect the subsamples by the experimental units (Plots).

Doing this takes two steps:

First, we average the subsamples of each Plot into a single number using the `aggregate` function:
```{r}
clover_means = aggregate(NLevel~Plot+Strain,clover,FUN = mean)
```

This says: "Find the mean of `NLevel` for each combination of `Plot` and `Strain`"
The output looks like this:
```{r}
str(clover_means)
```

and a boxplot, this time just of the plot means:
```{r}
ggplot(clover_means,aes(x=Strain,y=NLevel)) + geom_boxplot() + geom_jitter()
```
This is a more reasonable visualization because it's a more honest depicition of the variation in the experiment.

If we'd like, we can add the raw data on top of this plot like this:
```{r}
ggplot(clover,aes(x=Strain,y=NLevel)) + 
  geom_boxplot(data=clover_means) +  
  geom_point(data = clover_means,aes(fill = Plot),color = 'red',position = position_jitterdodge(),size = 3) +
  geom_point(data = clover, aes(fill = Plot),position = position_jitterdodge()) + 
  theme(legend.position = 'none') 
```

We can see that the `NLevel` of the subsamples of each plot clusters very closely around the Plot mean.

> Thought question:
>
> Is it worth doing subsamples of each plot in this case? How would you know?

- For a discussion, see later in the lab!


### Fit the model:

It looks like we do have large differences among the treatments. Let's see if the statistics
backs this up.

As discussed in class, we form our model statement from our design table:

`NLevel ~ Strain + (1|Plot)`

Notes:

- We do not include `Sample` in our model because it has the same number of levels as the Response
- We write `(1|Plot)` instead of just `Plot` because `Plot` is an Experiment Unit (of `Strain`)
- Because we have an experimental unit in our model statement, we have to fit the model with the `lmer()` function instead of `lm()`,

Putting this together, we fit our model like this:
```{r}
clover_model <- lmer(NLevel ~ Strain + (1|Plot), data = clover)
```


#### `lmer` vs `lm`
The two model fitting functions `lmer()` and `lm()` do pretty similar things for us, but they work very differently under the hood.
In general, you don't need to worry about this, and most of tools we'll use to analyze the output will work the same for either function.
However, there are a few differences in your R code depending on which function you use to analyze your data.
I'll try to point these out as we go. But if you're getting an error, make sure that you are using the code for the right function.


### Run diagnostic plots
We want to run the same diagnostics for this experiment as we ran for the Barley data in Lab 2.
In particular, we want to assess:

- Are the experimental units normally distributed?
- Is the variation of experimental units within each treatment approximately equal

Unfortunately, for models fit with `lmer()`, we have to do a bit more work for diagnostics than for models fit with `lm`.
The main reason is that we need to check assumptions for our *experimental units*, and we access these differently for the two functions.

- For the first assumption, we use a QQ-plot as in Lab 2.
- For the second assumption, we substitute a slightly different residuals plot that plots the absolute value of the residuals against the Strain means, called a *Scale-Location plot*. The idea here is not only to ask if the variation in EU's is different among strains, but to ask if there is a trend towards more or less variation for Strains with larger or smaller Response values, on average. This plot is more useful than the plot in Lab 2 when there are few values per strain, which is common in more complex experiments.

```{r}
# Step 1: Extract estimates of the experimental unit deviations
eu_data = aggregate(NLevel ~ Plot + Strain,clover,FUN = mean)  
  # this is like above - we're generating a new table with one row per plot
  # you'll have to adapt this for other experiments with other Variables
eu_data$deviation = ranef(clover_model)$Plot[clover_means$Plot,1] 
  # The key above is to substitute `Plot` for the name of your random experimental unit term above in both places
eu_data$fitted = predict(clover_model,newdata = eu_data,re.form = ~0)
  # This line you can use directly

# Step 2: Make QQplot and `Scale-Location` plot:
op = par(mfrow=c(1,2))  # two plots side-by-side
qqPlot(eu_data$deviation,main = 'Plot (EU) Normal Q-Q',pch=19)  # new qqplot function
scatter.smooth(eu_data$fitted,sqrt(abs(eu_data$deviation)),span = 1,main = 'Scale-Location',ylab = expression(sqrt(abs(' deviations '))),xlab = 'Fitted values')

# qqPlot(resid(clover.mod2), main = 'Residuals Normal Q-Q')
```

We do see some problems here. The residuals are a bit skewed (too many small values). 
And the Strain seem to vary some in their variances, 
with the Strain producing higher Nitrogen levels having slightly higher residuals variances (larger abs(deviations) towards the right of the graph). 
However, neither looks very severe.

We might want to stop here if we feel these devaitaions from our assumptions are too severe, or consider data transformations (a later lab). But we'll continue on for demonstration.

While our main concern is assumptions for our experimental units, it is also a good idea to check for problems in the observations themselves.
The deviations of the subsamples from the Plot means should also be normally distributed. 
For `lmer()` models, we can check this with another QQplot:
```{r}
qqPlot(resid(clover_model),pch=19)
```
This looks good here.

### Generate model summaries and tests
Most of these analyses can be run using the `emmeans` function:
```{r}
library(emmeans)
```

Using `emmeans` is basically the same with `lmer()` or `lm()` models, except that we have to add:
`lmer.df = 'k'` to the `emmeans()` function when we use `lmer()`

#### Treatment means
The first analysis we'll do is to simply estimate the mean Nitrogen Level for each of the 6 Strain.
```{r}
means_clover = emmeans(clover_model,specs = 'Strain', lmer.df = 'k')  # This preps an emmeans analysis, grouping by Strain
  # we give it a model (fit by lm() or lmer())
  # specs is the name of a variable to calculate over. In future examples, this will get more detailed
  # if our model is from lmer(), we include lmer.df = 'k'. 
summary(means_clover,level = 0.95,infer = c(T,F))  
  # set level (1-alpha) for the confidence intervals
  # infer = c(T,F) gives confidence intervals
  # infer = c(F,T) gives p-values intervals. Here these are testing against the null hypothesis that mu_i = 0
  # infer = c(T,T) gives both.
```

*emmean* is "estimated marginal means". 
The name is a bit confusing, but the idea is that this is the mean -- corrected for any other factors we've modeled (none in this case).
*SE* is the estimated SEM (the estimated standard error of this mean estimate)

> Thought questions:
> 
> If this is the $\hat{SEM}$, what is $s^2$? What is $\hat{SED}$ for the difference between 3DOk1 - Comp?


#### Treatment differences
With 6 levels of the treatment, there are several ways of describing differences.

1. We could compare each of the Strain to a single control treatment
2. We could compare all pairs of Strain

#### Confidence intervals and hypothesis tests for differences between each new Strain and control
We tell `emmeans` to measure the effects of each treatment against the control using the `contrast()` function 
with argument `method = 'trt.vs.ctrl'`. We must specify which of the levels of `Strain` is our control.
You can see how R orders treatments like this:
```{r}
levels(clover$Strain)
```

"Comp" is the 6th level of the variable `Strain` in the data.frame `clover`. 
Therefore we specify `ref = 6`

```{r}
differences_vs_control = contrast(means_clover,method = 'trt.vs.ctrl',ref = 6)  # ref = 6, because the control is the 6th Strain
summary(differences_vs_control,level = 0.95,infer = c(T,F))
```

Note: The summary states that the **dunnettx** method was used to adjust the level of the confidence intervals.
This is the correct adjustment for comparisons of treatments against a single control. 

This adjustment works by calculating a new **penalty** statistic to replate $t_{\alpha/2,df}$ in
the formula for a confidence interval.

The **p.value** for each test is also adjusted so that it is a **simultaneous** p-value for all the tests.
It represents the probability that the **biggest** difference among any of the 5 `3DOk` Strain against
the control would be at least as large as the biggest observed difference **if all 5 were unchanged** relative to the control.

#### Confidence intervals for pairwise differences among all Strain
We tell `emmeans` to form all pairwise comparisons with the argument `method = 'pairwise'` to the `contrast()` function:
```{r}
pairwise_differences = contrast(means_clover,method = 'pairwise')
summary(pairwise_differences,level = 0.95,infer = c(T,F))
```

#### Exercise: Form the treatments into groups
Making sense of all these pairwise comparisons (also called **contrasts**) is challenging.

One common strategy is to form the treatments into groups, where all treatments that cannot
be significantly distinguished are in the same group, and all treatments that can be distinguished
(at a specific alpha) are in different groups. Commonly groups are assigned letters ("a","b","c", etc)
or numbers ("1","2","3").

By "distinguished" here, we mean that we can reject the **null hypothesis** that $\mu_i = \mu_j$,
and that the chance of incorrectly stating that **any pair** of treatments is different when they are
actually all the same is $\alpha$*100.

The strategy for forming these groups is the following:

1. Find the **minimum significant difference** that can be distinguished. 
Remember, a difference is **significant** if its confidence interval does not cross zero.
The confidence interval is $\hat{\delta} \pm t_c * SED$ (mouse-over to see the equation rendered).
So, two treatments are different if $|\hat{\delta}| > t_c * SED$. 
  - find SED (*hint: look at the pairwise difference table above*)
```{r}
SED =  000 # replace by the correct number.
```
  - Find t_c. This will come from the Tukey distribution instead of the t-distribution. The Quantile 
  function of this distribution is `qtukey`. Alternatively, you could use the confidence intervals
  above to calculate it!
```{r}
# Note: using qtukey is a bit different than qt. 
#   You also have to enter the number of groups (nmeans)
#   The value that you give out needs to be divided by sqrt(2)
#   The tukey distribution is "folded", so it counts negative and positive differences the same.
#   This means we use it like a one-sided distribution, and use p=alpha (instead of p=alpha/2) 
c_q = qtukey(p = 0.05,nmeans = 6,df = 24,lower.tail = F) / sqrt(2)
c_q
# instead, from the confidence interval of the first contrast above: (22.27416704-8.845833)/(2*SED)
```
  - The minimim significant difference is then `c_q * SED`
```{r}
MSD = c_q * SED
MSD
```
  
2. Order the treatments from smallest to largest by their mean (`emmean`)

| # | Treatment | Mean | Letters |
|---|-----------|------|---------|
| 1 |           |      |         |
| 2 |           |      |         |
| 3 |           |      |         |
| 4 |           |      |         |
| 5 |           |      |         |
| 6 |           |      |         |

3. Start with the smallest treatment. Assign this an **a**. Then moving up the list of treatments,
label all treatments with an **a** if they are within `MSD` of the first treatment.
4. When you get to a treatment that can be distinguished from the first, label this treatment **b**.
5. Now, find the first treatment (from the top) that is NOT distinguishable from the first **b**. Add a **b** to this treatment.
Note: treatments can receive multiple letters!
6. Now, repeat step 3 starting with the smallest **b** treatment.
7. Repeat 4-6 for **c**, **d**, etc, until you label the last treatment.

Do this on paper or in the table above. Work with those around you.


#### Compact letter display with emmeans
This is a bit of work. Fortunately, the `multcomp` package has a function `cld` that will do this for you!
```{r}
cld(means_clover,level = 0.95,Letters = letters)
```

---

## Optimal Number of Subsamples
Returning to a question earlier in the lab:

*Was it worth taking 4 subsamples per plot?*

The calculations for this are described in the file `Optimal_number_subsamples.Rmd` on `Class 5` folder on Canvas.

To answer, we need to calculate 2 ratios:

- The ratio of the costs of subsamples to experimental units (Plots)
- The ratio of the variance of subsamples to the variance of experimental units

Here, the cost of a subsample is the cost of the soil analysis (as we assume the act of sampling soil is pretty quick). The cost of a Plot is a field cost - $ per acre. 
I don't know the relative costs here, so lets assume the soil analysis is $10 per sample, and the field ~$3000 for the 30 plots.

To get estimates of the variance of subsamples and Plots, we can use the function `VarCorr()`:
```{r}
VarCorr(clover_model)
```

This says that the standard deviation of Plots was 3.4, and of Samples (in plots) was 0.8.

Putting this together, we have c = 10/100 and k = .8^2/3.4^2, so the optimal number of subsamples is:
$$\sqrt{k/c} = \sqrt{(.8/3.4)^2 * 10} = 0.7$$
So the optimal experiment for a fixed cost would have 1 subsamples. 
The 4 that were actually taken are a bit of a waste of resources that would have been better allocated
to new plots.

---

## Data entry problems

It is **very** important to carefully inspect how R loaded your data. 

I've taken the exact same clover data and saved it in a new file (`Clover_data_Renamed.csv`), but named the Strain 1:6. 

Load this data and repeate the abova ANOVA. Do you get the same answer? What is wrong?
```{r}
# load data and view
clover_renamed <- read.csv("Clover_data_renamed.csv")
str(clover_renamed)
```
> **Note** Strain is an `int`, not a `Factor`! 

Proceed anyway and fit the model try to get treatment means
```{r}
clover_model_v2 <- lmer(NLevel ~ Strain + (1|Plot), data = clover_renamed)

means_clover_v2 = emmeans(clover_model_v2,spec = 'Strain',lmer.df = 'k')
summary(means_clover_v2,level = 0.95,infer = c(T,F))
```

This is basically meaningless (an estimate of the mean weed biomass for Strain 3.5).

You can fix this by running this right after loading the data:
```{r eval = F}
clover_renamed$Strain = as.factor(clover_renamed$Strain)
clover_model_v3 <- lmer(NLevel ~ Strain + (1|Plot), data = clover_renamed)

means_clover_v3 = emmeans(clover_model_v3,spec = 'Strain',lmer.df = 'k')
summary(means_clover_v3,level = 0.95,infer = c(T,F))
```


