--- 
title: "Lab 7. The relationship between factorials and blocked designs" 
author: Daniel Runcie. Modified from labs designed by Iago Hale, Dario Cantu and Jorge Dubcovsky 
output: 
  html_notebook: 
    toc: true 
    toc_float: true 
--- 
```{r} 
# Necessary pacakges 
library(ggplot2) 
library(emmeans)
```

## The relationship between factorials and blocked designs

The analysis of a RCBD and a factorial design are very similar. In both cases, you have multiple
factors that are **crossed**, meaning levels of one factor are tested in combination with different
levels of another factor. The main difference between a RCBD and a factorial is in the experiment's
goals. In a factorial, the intent is to measure the effect of both factors, and (usually) their
interaction. In a RCBD, the goal is to improve the precision of the treatment(s), and the effects of
the blocking factors, or interactions with the treatment are not of interest.

We usually say that a factorial design is not an "experimental design", but a "treatment design",
which can be placed into any "experimental design" like a RCBD. In the following example, the
experimental design is an RCBD and the treatment design is a factorial.

## RCBD analysis
In a study comparing the relative growth of five varieties of turfgrass (VARIETY) in
three experimental soil mixtures (SOIL). Six pots were prepared with each VARIETY-SOIL combination. 
One pot from each of the 15 VARIETY-SOIL combinations was placed in each of six growth chambers
(BLOCKS) and the dry matter yields were measured by clipping the plants at the end of four weeks. 
The six growth chambers were needed to accomodate all 90 pots, but differences among
growth chambers were not of interest.

### Load the data and inspect 
```{r} 
RCBD_data <- read.csv('RCBD_data.csv') 
str(RCBD_data) 
```

Set all class variables to factors. **This is critical!**
```{r} 
RCBD_data$Soil = factor(RCBD_data$Soil) 
RCBD_data$Variety = factor(RCBD_data$Variety) 
RCBD_data$Block = factor(RCBD_data$Block) 
```

### Model table 
The full model table looks like this:

| Structure | Variable           | Type        | # levels | Experimental Unit |
|-----------|--------------------|-------------|----------|-------------------|
| Treatment | Variety            | Categorical | 5        | Pot               |
|           | Soil               | Categorical | 3        | Pot               |
|           | Soil:Variety       | Categorical | 15       | Pot               |
| Design    | Block              | Categorical | 6        |                   |
|           | Block:Variety      | Categorical | 30       |                   |
|           | Block:Soil         | Categorical | 18       |                   |
|           | Block:Soil:Variety | Categorical | 90       |                   |
|           | Pot                | Categorical | 90       |                   |
| Response  | Yield              | Categorical | 90       |                   |

> Note: We only list Experimental Units for the Treatments.

### Data exploration
Before we actually analyze these data, lets take a look at them graphically.

#### Treatment interaction plot
Since the goal of this experiment is to study the interactions between Varieties and Soils, lets start with an interaction plot.
In this plot, we'll use the `geom_smooth` function to average the replicates of each Soil separately for each Variety, 
and then add confidence intervals around this mean.

```{r}
ggplot(RCBD_data,aes(x=Variety,y=Yield)) + 
  geom_smooth(aes(group = Soil,color = Soil),method = 'lm',formula = 'y~factor(x)')
```

> From this, it appears the Soil effect does differ among Varieties. Soil 1 appears much better for Variety 4, and Soil 3 appears worse for Variety 3.
> The Soils don't seem to differ much for Varieties 1-3.
> These are the types of conclusions we'd like to be able to draw. However, the confidence intervals around each of the 5x3 = 15 means are large.

To see why they are large, let's look at the raw data instead of the means.
We can use the `facet_wrap` function in ggplot to make separate plots for each Variety

#### Raw data by Variety
```{r}
ggplot(RCBD_data,aes(x=Soil,y=Yield)) + 
  geom_jitter(width = 0.1) + 
  facet_wrap(~Variety,labeller = label_both) # This line separates the plots into separate plots for each Variety
```

> We see that the variation within each Soil:Variety combination is large.

To explore further, let's make the same plot, but color each point by which Block they came from:

#### Raw data by Variety colored by Block
```{r}
ggplot(RCBD_data,aes(x=Soil,y=Yield)) + 
  geom_jitter(aes(color = Block),width = 0.1) + 
  facet_wrap(~Variety,labeller = label_both) # This line separates the plots into separate plots for each Variety
```

> The is a lot of noise, but if you look closely, you can see that Block 6 jumps out as always having about the highest yield.

#### Block variation
Let's just plot the data by Block:
```{r}
ggplot(RCBD_data,aes(x=Block,y=Yield)) + geom_boxplot()
```

> Now it's clear that Block 6 has very high values. 
> This is introducing a lot of variation into our replicates (see dot plot above)
> But since each treatment was represented once in this block, we should be able to correct for this block effect statisticallty.

#### Separate interaction plots in each Block
The way to think about an RCBD analysis is as a separate analysis within each block, with the answers combined across blocks.
Let's make our interaction plots within each block using `ggplot`:

```{r}
ggplot(RCBD_data,aes(x=Variety,y=Yield)) + 
  geom_line(aes(group = Soil,color = Soil)) + 
  facet_wrap(~Block,labeller = label_both) # This line separates the plots into separate plots for each Block
```

> Note: we don't have error bars here because these Variety:Soil combinations are not replicated within blocks, so we can't create confidence intervals.
> However, do you see any consistency among the blocks?

> Although the data are somewhat noisy, I see that Soil 1 is consistently (across all 6 blocks) the best for Variety 4, 
> and Soil 3 is consistently the worst for Variety 5. 
> These statements are true in 6/6 blocks. That's pretty decent replication.
> So it seems our the confidence in these conclusions should be pretty high, despite the wide confidence intervals we saw above.

### Statistical analysis of the Factorial in an RCBD
Refer back to the model table we created at the start. Given this, we should be able to write a linear model for these data.

The full linear model is:

```{r}
full_model <- lm(Yield ~ Variety + Soil + Variety:Soil + Block + Block:Soil + Block:Variety,RCBD_data)
```

To get here, we included all terms in the table with fewer levels than the number of observations.

#### Model diagnostics
We will start with the standard diagnostics for any model: QQ-plots and Scale-location plots:
```{r}
par(mfrow=c(1,2))
plot(full_model,which=2:3)
```

> These plots look fine to me. Very close to normal distributions, and little trend in errors across fitted values.

#### Block:treatment interactions
Now, we add a new type of diagnostics: we try to assess whether the treatment effects differ across the blocks.
If they do, we can still analyze the experiment, but the interpretation becomes a bit less clear.
If treatment effects differ a lot across blocks, then what is the **true** treatment effect? Is the **average** treatment effect useful?

Depending on the experiment, we have 2 ways to assess whether there are block:treatment interactions.

1. ANOVA
2. Diagnostic plots and visualizations

If treatments are replicated within blocks, we can include the block:treatment term in our model and test it by ANOVA. If not, we have to use plots.

In this experiment, we have 3 treatment effects: `Variety`, `Soil` and `Variety:Soil`. The first two have `Block:Variety` and `Block:Soil` terms in our model. So, we can assess these interactions by ANOVA:

```{r}
anova(full_model)
```

> Note: right now, we are only interested in the `Soil:Block` and `Variety:Block` terms. Also, for diagnostics, it's not good to only rely on p-values. We're trying to assess how important the interactions are, not test if they are exactly zero. So the MSI values are maybe more important.

Here, the MSI for `Variety:Block` is 19.6, vs the MST for `Variety` is 23, so we're estimating that the Variety effects change a lot across blocks relative to the average Variety size.
On the other hand, the MSI for `Soil:Block` is 9.2 vs the MST for `Soil` is 290, so the change in Soil effects across Blocks is small relative to the average Soil effects. 
So, our diagnostics here say that we should be more cautious about interpreting Variety main effects here than Soil main effects (since Variety effects change more among blocks than the Soil effects)

But... the goal of the experiment isn't really to study these main effects, it's to study the `Variety:Soil` interaction. And we can't test the `Block:Variety:Soil` interactions in this way.

Our remaining option is to assess for evidence of interactions graphically. 
The idea of the graphical analysis is that if we see a strong pattern to how the treatment effects differ among blocks,
then we can infer that there are interactions.

The most common pattern that we are likely to see is that treatment differences are bigger for blocks with higher means.
This is called a **multiplicative interaction**. 
The pattern would be that if we order the blocks by their mean, we'd see greater variation among treatments in the larger blocks, and less variation in the smaller blocks.

There are two common plots we can make to look for this pattern:

#### The first is to make an interaction plot of this intercation term across Blocks.
```{r}
# first get the block means
block_means = aggregate(Yield~Block,RCBD_data,FUN=mean)
# order the table of block_means
block_means = block_means[order(block_means$Yield),]
block_means
```

```{r}
library(ggplot2)
# now, re-order the levels of `Block` in order of the block means
RCBD_data$Block2 = factor(RCBD_data$Block,levels = block_means$Block)
ggplot(RCBD_data,aes(x=Block2,y=Yield)) + geom_line(aes(group=interaction(Variety,Soil),color = interaction(Variety,Soil)))
```

> In this plots, you should look for trends towards bigger differences among the treatment levels for Blocks with bigger means. 
> Blocks on the x-axis are ordered by their mean Yield.
> Here we don't see a lot of trend. The variances among the Variety:Soil combinations are relatively constant across blocks
> Therefore, we do not see strong evidence for a multiplicative interaction for Block:(Variety:Soil)

#### The second is to look at the model residuals plots again:
```{r}
par(mfrow=c(1,2))
plot(full_model,which=2:3)
```

> A multiplicative interaction would show as a "U-shape" in the Scale-Location plot. Look for this in the HW!

Overall, we do not see any sign of problems in this analysis with block:treatment interactions.

### Analysis of the factorial

The rest of the analysis of the experiment is exactly the same as for a basic factorial. Once you've 
included the `Block` term in your model, you can simply ignore it in all future analyses.

Decide whether the interaction is important:
```{r}
anova(full_model)
```

> For this, ONLY look at the `Variety:Soil` row.

If it is, report simple effects:
```{r}
means = emmeans(full_model,specs = c('Soil','Variety'))
contrasts_by_Variety = contrast(means,method='pairwise',by='Variety')
summary(contrasts_by_Variety,infer=T,level = 1-(0.05/5))  # Bonferroni adjustment for 5 tables of contrasts (one for each variety)
```

> Now, we see the clear differences among Soils for Variety 4 and 5 that we saw visually, but didn't come out in the original plots.
> Note: remember the Bonferroni correction above. emmeans does not do it automatically when running separate analyses for each variety with the `by=Variety` argument above.

We can visualize these results like this:
```{r}
plot(contrasts_by_Variety)
```

### Was blocking worth it?
In this design, blocking introduced complications into the analysis (all those interactions), and reduced the 
degrees of freedom for the statistical tests. Blocking only would have been worth it if it reduced MSE sufficiently to compensate.

```{r}
anova(full_model)
```

```{r}
no_block_model = lm(Yield ~ Variety + Soil + Variety:Soil,data = RCBD_data)
anova(no_block_model)
```


> Here, the Block terms explain a lot of variance. The MSB value is very large, and the p-value is very small.
> More directly, the p-value for `Variety:Soil` is much smaller when we include the Block terms in the model, and MSE is much smaller.
> Therefore, using Blocking probably helped a lot.

> For a more formal method for assessing the value of blocks, see the file: L6_RCBD.pdf under Class 13/Readings.
